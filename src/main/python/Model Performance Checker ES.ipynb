{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from modules.ONS import queries\n",
    "reload(queries)\n",
    "\n",
    "index = \"ons1515656903908\"\n",
    "\n",
    "models = []\n",
    "for i in range(9):\n",
    "    modelName = \"ons_model_%d\" % (i+1)\n",
    "    models.append(modelName)\n",
    "\n",
    "boosts = [1.0]*9\n",
    "queryWeights = [0.5]*9\n",
    "rescoreWeights = [1.0]*9\n",
    "\n",
    "size = 10\n",
    "\n",
    "searchTerms = [\"rpi\", \"gender pay gap\", \"cpi\", \"gdp\", \"inflation\", \"crime\", \"unemployment\", \n",
    "              \"population\", \"immigration\", \"mental health\", \"london\", \"london population\", \n",
    "              \"retail price index\", \"life expectancy\", \"obesity\", \"religion\", \"migration\", \n",
    "              \"poverty\", \"social media\", \"employment\"]\n",
    "\n",
    "qidDict = {}\n",
    "for i in range(len(searchTerms)):\n",
    "    qidDict[i+1] = searchTerms[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "esUrl = \"http://localhost:9200\"\n",
    "esClient = Elasticsearch(esUrl, timeout=1000)\n",
    "\n",
    "from pymongo import MongoClient, ASCENDING, DESCENDING\n",
    "mongoClient = MongoClient('localhost', 27017)\n",
    "\n",
    "db = mongoClient.local\n",
    "collection = db.judgements\n",
    "\n",
    "def mergeDicts(x, y):\n",
    "    z = x.copy()   # start with x's keys and values\n",
    "    z.update(y)    # modifies z with y's keys and values & returns None\n",
    "    return z\n",
    "\n",
    "def termQuery(term):\n",
    "    return {\"term\": term}\n",
    "\n",
    "def timeQuery(dateTime):\n",
    "    return {\"timeStamp\": dateTime}\n",
    "\n",
    "# Get date of most recent entries\n",
    "doc = collection.find().sort([(\"timeStamp\", DESCENDING)]).limit(1).next()\n",
    "timeStamp = doc[\"timeStamp\"]\n",
    "    \n",
    "timeStampQuery = timeQuery(timeStamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "MAX_SCORE = 4.0\n",
    "\n",
    "def idealJudgement(num):\n",
    "    i = 0\n",
    "    incremenet = (1.0 / (float(num) - 1.0)) * num\n",
    "    \n",
    "    iJ = np.zeros(num)\n",
    "    val = len(iJ)\n",
    "    while (val > 0):\n",
    "        iJ[i] = (val / float(num)) * MAX_SCORE\n",
    "        i += 1\n",
    "        val -= incremenet\n",
    "        \n",
    "    return iJ\n",
    "\n",
    "def idealDiscountedCumulativeGain(num):\n",
    "    idealGain = idealJudgement(num)\n",
    "    iDCG = np.zeros(num)\n",
    "    \n",
    "    total = 0.0\n",
    "    for i in range(num):\n",
    "        total += idealGain[i] / float(i+1)\n",
    "        iDCG[i] = total\n",
    "    return iDCG\n",
    "\n",
    "class Judgements(object):\n",
    "    def __init__(self, judgements):\n",
    "        self.judgements = judgements\n",
    "        \n",
    "    def dcg(self):\n",
    "        total = 0.0\n",
    "        \n",
    "        dcg = []\n",
    "        \n",
    "        for i in range(len(self.judgements)):\n",
    "            judgement = self.judgements[i]\n",
    "            total += judgement[\"judgement\"] / float(judgement[\"rank\"])\n",
    "            dcg.append(total)\n",
    "            \n",
    "        return np.array(dcg)\n",
    "    \n",
    "    def ndcg(self):\n",
    "        \n",
    "        dcg = self.dcg()\n",
    "        idcg = idealDiscountedCumulativeGain(len(dcg))\n",
    "        \n",
    "        ndcg = np.zeros(len(dcg))\n",
    "        \n",
    "        for i in range(len(ndcg)):\n",
    "            ndcg[i] = min(1.0, dcg[i] / idcg[i])\n",
    "        return ndcg\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.judgements.__iter__()\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.judgements[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.judgements)\n",
    "    \n",
    "    def remove(self, item):\n",
    "        self.judgements.remove(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy, json\n",
    "\n",
    "def processTerm(searchTerm, boosts, queryWeights, rescoreWeights, pages=10):\n",
    "    mongoQuery = mergeDicts(termQuery(searchTerm), timeStampQuery)\n",
    "    cursor = collection.find(mongoQuery)\n",
    "    judgementCount = cursor.count()\n",
    "    \n",
    "    if (judgementCount > 0):\n",
    "        judgements = cursor.next()\n",
    "        modelJudgements = copy.deepcopy(judgements)\n",
    "\n",
    "        keep = []\n",
    "        judgementList = modelJudgements[\"judgements\"][\"judgementList\"]\n",
    "        \n",
    "        # Reset ranks\n",
    "        for judgement in judgementList:\n",
    "            judgement[\"rank\"] = -1\n",
    "        \n",
    "        rescoreQueries = queries.getRescoreQueriesForModels(searchTerm, models, boosts, queryWeights, rescoreWeights)\n",
    "        for page in range(1, pages+1):\n",
    "            fromParam = (page - 1) * size\n",
    "            esQuery = queries.getBaseQuery(searchTerm, rescoreQueries, fromParam, size)\n",
    "#             print json.dumps(esQuery)\n",
    "\n",
    "            hits = esClient.search(index=index, body=esQuery)\n",
    "            \n",
    "#             print \"Got %d hits for page %d\" % (len(hits[\"hits\"][\"hits\"]), page)\n",
    "            \n",
    "            searchResults = []\n",
    "            for hit in hits[\"hits\"][\"hits\"]:\n",
    "                searchResults.append( hit[\"_id\"] )\n",
    "            \n",
    "            # Check for matches\n",
    "            for judgement in judgementList:\n",
    "                url = judgement[\"attrs\"][\"uri\"]\n",
    "                if (url in searchResults):\n",
    "                    newRank = int(((page - 1) * 10.0) + searchResults.index(url) + 1)\n",
    "                    judgement[\"rank\"] = newRank\n",
    "                    j = copy.deepcopy(judgement)\n",
    "                    j[\"rank\"] = newRank\n",
    "                    keep.append(j)\n",
    "                    \n",
    "        if (len(keep) > 1):\n",
    "            judgementList = Judgements(keep)\n",
    "            ndcg = judgementList.ndcg()\n",
    "#             print searchTerm, ndcg.mean()\n",
    "            return ndcg.mean()\n",
    "    else:\n",
    "        return 0.0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75368310310807696"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processTerm(\"rpi\", boosts, queryWeights, rescoreWeights)\n",
    "# for qid in qidDict:\n",
    "#     processTerm(qid, qidDict[qid], weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import random\n",
    "# import numpy as np\n",
    "\n",
    "# X = []\n",
    "# for i in range(10):\n",
    "#     W = np.zeros(len(models))\n",
    "#     for j in range(len(models)):\n",
    "#         W[j] = random.random()\n",
    "#     X.append(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 100.0), (0.0, 100.0), (0.0, 100.0), (0.0, 100.0), (0.0, 100.0), (0.0, 100.0), (0.0, 100.0), (0.0, 100.0), (0.0, 100.0)]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "reload(queries)\n",
    "\n",
    "X = [(0.0, 100.0)]*len(models)\n",
    "\n",
    "# X = [(0.0, 1.0)]*len(models)\n",
    "# X.extend([(0.0, 100.0)]*len(models))\n",
    "def fn(X):\n",
    "#     queryWeights, rescoreWeights = np.split(np.array(X), 2)\n",
    "    term = random.choice(searchTerms)\n",
    "#     ndcg = processTerm(term, boosts, queryWeights, rescoreWeights)\n",
    "    ndcg = processTerm(term, boosts, queryWeights, X)\n",
    "    if (ndcg is None):\n",
    "        return 1.0\n",
    "    return 1.0 - ndcg\n",
    "print X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing...\n"
     ]
    }
   ],
   "source": [
    "from skopt import gp_minimize\n",
    "from skopt import Optimizer\n",
    "\n",
    "print \"Optimizing...\"\n",
    "res = gp_minimize(fn, X, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rpi 0.752345044613\n",
      "gender pay gap 0.381042769502\n",
      "cpi 0.875\n",
      "gdp 0.857279266168\n",
      "inflation 0.625943113654\n",
      "crime 0.63212293121\n",
      "unemployment 0.331586267837\n",
      "population 0.273889506311\n",
      "immigration 0.788106496236\n",
      "mental health 0.636923056164\n",
      "london None\n",
      "london population 1.0\n",
      "retail price index 0.671139674231\n",
      "life expectancy 0.0371328264369\n",
      "obesity 0.0\n",
      "religion 0.568614989855\n",
      "migration 0.157618326452\n",
      "poverty 0.389800284551\n",
      "social media 0.961466992539\n",
      "employment 0.585233426968\n"
     ]
    }
   ],
   "source": [
    "print res.x\n",
    "\n",
    "queryWeightsNew, rescoreWeightsNew = np.split(np.array(res.x), 2)\n",
    "\n",
    "count = 0\n",
    "for searchTerm in searchTerms:\n",
    "    count += 1\n",
    "    ndcg = processTerm(count, searchTerm, boosts, queryWeightsNew, rescoreWeightsNew)\n",
    "    print searchTerm, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "[0.91512786228791776, 0.18637723563018363, 0.092858794570568129, 0.53273612668253156,\n",
    " 0.76706400990704571, 0.58349107122737787, 0.6834580839907477, 0.88558707199299047,\n",
    " 0.48277903739251804, 6.1817401341518003, 9.7805931268469362, 9.3722047829479767,\n",
    " 4.713174354828487, 2.601749548125281, 4.3597225473416383, 8.9907343794135848,\n",
    " 6.4090652493697053, 2.9974113081044855]\n",
    "\n",
    "Out[53]:\n",
    "0.76181999486796548"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
