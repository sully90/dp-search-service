{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from modules.ONS import queries\n",
    "\n",
    "index = \"ons1516722910092\"\n",
    "store = \"ons_featurestore_1516779508509\"\n",
    "\n",
    "boosts = [1.0]*len(models)\n",
    "queryWeights = [0.5]*len(models)\n",
    "rescoreWeights = [1.0]*len(models)\n",
    "\n",
    "size = 10\n",
    "\n",
    "searchTerms = [\"rpi\", \"gender pay gap\", \"cpi\", \"gdp\", \"inflation\", \"crime\", \"unemployment\", \n",
    "              \"population\", \"immigration\", \"mental health\", \"london\", \"london population\", \n",
    "              \"retail price index\", \"life expectancy\", \"obesity\", \"religion\", \"migration\", \n",
    "              \"poverty\", \"social media\", \"employment\"]\n",
    "\n",
    "qidDict = {}\n",
    "for i in range(len(searchTerms)):\n",
    "    qidDict[i+1] = searchTerms[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "esUrl = \"http://localhost:9200\"\n",
    "esClient = Elasticsearch(esUrl, timeout=1000)\n",
    "\n",
    "from pymongo import MongoClient, ASCENDING, DESCENDING\n",
    "mongoClient = MongoClient('localhost', 27017)\n",
    "\n",
    "db = mongoClient.local\n",
    "collection = db.judgements\n",
    "\n",
    "def mergeDicts(x, y):\n",
    "    z = x.copy()   # start with x's keys and values\n",
    "    z.update(y)    # modifies z with y's keys and values & returns None\n",
    "    return z\n",
    "\n",
    "def termQuery(term):\n",
    "    return {\"term\": term}\n",
    "\n",
    "def timeQuery(dateTime):\n",
    "    return {\"timeStamp\": dateTime}\n",
    "\n",
    "# Get date of most recent entries\n",
    "doc = collection.find().sort([(\"timeStamp\", DESCENDING)]).limit(1).next()\n",
    "timeStamp = doc[\"timeStamp\"]\n",
    "    \n",
    "timeStampQuery = timeQuery(timeStamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "MAX_SCORE = 4.0\n",
    "\n",
    "def idealJudgement(num):\n",
    "    i = 0\n",
    "    incremenet = (1.0 / (float(num) - 1.0)) * num\n",
    "    \n",
    "    iJ = np.zeros(num)\n",
    "    val = len(iJ)\n",
    "    while (val > 0):\n",
    "        iJ[i] = (val / float(num)) * MAX_SCORE\n",
    "        i += 1\n",
    "        val -= incremenet\n",
    "        \n",
    "    return iJ\n",
    "\n",
    "def idealDiscountedCumulativeGain(num):\n",
    "    idealGain = idealJudgement(num)\n",
    "    iDCG = np.zeros(num)\n",
    "    \n",
    "    total = 0.0\n",
    "    for i in range(num):\n",
    "        total += idealGain[i] / float(i+1)\n",
    "        iDCG[i] = total\n",
    "    return iDCG\n",
    "\n",
    "class Judgements(object):\n",
    "    def __init__(self, judgements):\n",
    "        self.judgements = judgements\n",
    "        \n",
    "    def dcg(self):\n",
    "        total = 0.0\n",
    "        \n",
    "        dcg = []\n",
    "        \n",
    "        for i in range(len(self.judgements)):\n",
    "            judgement = self.judgements[i]\n",
    "            total += judgement[\"judgement\"] / float(judgement[\"rank\"])\n",
    "            dcg.append(total)\n",
    "            \n",
    "        return np.array(dcg)\n",
    "    \n",
    "    def ndcg(self):\n",
    "        \n",
    "        dcg = self.dcg()\n",
    "        idcg = idealDiscountedCumulativeGain(len(dcg))\n",
    "        \n",
    "        ndcg = np.zeros(len(dcg))\n",
    "        \n",
    "        for i in range(len(ndcg)):\n",
    "            ndcg[i] = min(1.0, dcg[i] / idcg[i])\n",
    "        return ndcg\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.judgements.__iter__()\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.judgements[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.judgements)\n",
    "    \n",
    "    def remove(self, item):\n",
    "        self.judgements.remove(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy, json\n",
    "reload(queries)\n",
    "\n",
    "def processTerm(searchTerm, rescoreQueries, pages=10):\n",
    "    mongoQuery = mergeDicts(termQuery(searchTerm), timeStampQuery)\n",
    "    cursor = collection.find(mongoQuery)\n",
    "    judgementCount = cursor.count()\n",
    "    \n",
    "#     print judgementCount\n",
    "    \n",
    "    if (judgementCount > 0):\n",
    "        judgements = cursor.next()\n",
    "        modelJudgements = copy.deepcopy(judgements)\n",
    "\n",
    "        keep = []\n",
    "        judgementList = modelJudgements[\"judgements\"][\"judgementList\"]\n",
    "        \n",
    "        # Reset ranks\n",
    "        for judgement in judgementList:\n",
    "            judgement[\"rank\"] = -1\n",
    "            \n",
    "        for page in range(1, pages+1):\n",
    "            fromParam = (page - 1) * size\n",
    "            esQuery = queries.getBaseQuery(searchTerm, rescoreQueries, fromParam, size)\n",
    "#             print json.dumps(esQuery)\n",
    "\n",
    "            hits = esClient.search(index=index, body=esQuery)\n",
    "            \n",
    "#             print \"Got %d hits for page %d\" % (len(hits[\"hits\"][\"hits\"]), page)\n",
    "            \n",
    "            searchResults = []\n",
    "            for hit in hits[\"hits\"][\"hits\"]:\n",
    "                searchResults.append( hit[\"_id\"] )\n",
    "            \n",
    "            # Check for matches\n",
    "            for judgement in judgementList:\n",
    "                url = judgement[\"attrs\"][\"uri\"]\n",
    "                if (url in searchResults):\n",
    "                    newRank = int(((page - 1) * 10.0) + searchResults.index(url) + 1)\n",
    "                    judgement[\"rank\"] = newRank\n",
    "                    j = copy.deepcopy(judgement)\n",
    "                    j[\"rank\"] = newRank\n",
    "                    keep.append(j)\n",
    "                    \n",
    "        if (len(keep) > 1):\n",
    "            judgementList = Judgements(keep)\n",
    "            ndcg = judgementList.ndcg()\n",
    "#             print searchTerm, ndcg.mean()\n",
    "            return ndcg.mean()\n",
    "    return 0.0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rpi 0.356146510737\n",
      "gender pay gap 0.381344038499\n",
      "cpi 0.0\n",
      "gdp 0.160264666305\n",
      "inflation 0.0370843059288\n",
      "crime 0.143854525553\n",
      "unemployment 0.21582871965\n",
      "population 0.0\n",
      "immigration 0.456859258023\n",
      "mental health 0.512500000497\n",
      "london 0.0679613965191\n",
      "london population 0.0570700817232\n",
      "retail price index 0.01789268271\n",
      "life expectancy 0.220139297464\n",
      "obesity 0.0\n",
      "religion 0.654906862714\n",
      "migration 0.0497563845439\n",
      "poverty 0.497389945727\n",
      "social media 0.0171233752585\n",
      "employment 0.0\n"
     ]
    }
   ],
   "source": [
    "# processTerm(\"rpi\", boosts, queryWeights, rescoreWeights)\n",
    "\n",
    "model = \"ons_model_9\"\n",
    "for searchTerm in searchTerms:\n",
    "    rescoreQuery = queries.getRescoreQueriesForModel(store, searchTerm, model, 1.0, 0.5, 1.0)\n",
    "    ndcg = processTerm(searchTerm, [rescoreQuery])\n",
    "    print searchTerm, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fn(searchTerm, model, X, doPrint=False):\n",
    "    b,q,r = X\n",
    "#     ndcg = processTerm(term, boosts, queryWeights, rescoreWeights)\n",
    "    rescoreQuery = queries.getRescoreQueriesForModel(store, searchTerm, model,\n",
    "                        b, q, r)\n",
    "    ndcg = processTerm(searchTerm, [rescoreQuery])\n",
    "    if (ndcg is None):\n",
    "        return 0.0\n",
    "    return ndcg\n",
    "\n",
    "def optFn(searchTerm, model, X):\n",
    "    ndcg = fn(searchTerm, model, X)\n",
    "    if (ndcg is None):\n",
    "        return 1.0\n",
    "    return 1.0 - ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************\n",
      "model= ons_model_3\n",
      "************************************\n",
      "Optimizing for term: 'rpi'\n",
      "rpi 0.354292432122 0.707080232398\n",
      "Optimizing for term: 'gender pay gap'\n",
      "gender pay gap 0.381040746355 0.382396093272\n",
      "Optimizing for term: 'cpi'\n",
      "cpi 0.0734986367799 1.0\n",
      "Optimizing for term: 'gdp'\n",
      "gdp 0.16262626861 0.855459211232\n",
      "Optimizing for term: 'inflation'\n",
      "inflation 0.0378790390385 0.354376658565\n",
      "Optimizing for term: 'crime'\n",
      "crime 0.143218872422 0.747571841401\n",
      "Optimizing for term: 'unemployment'\n",
      "unemployment 0.162617662551 0.162617662551\n",
      "Optimizing for term: 'population'\n",
      "population 0.0 0.713476287431\n",
      "Optimizing for term: 'immigration'\n",
      "immigration 0.456780739083 0.767874542656\n",
      "Optimizing for term: 'mental health'\n",
      "mental health 0.501562500062 0.501562500062\n",
      "Optimizing for term: 'london'\n",
      "london 0.0476104922472 0.507852506166\n",
      "Optimizing for term: 'london population'\n",
      "london population 0.0 0.923068674973\n",
      "Optimizing for term: 'retail price index'\n",
      "retail price index 0.0375022920651 0.601811239855\n",
      "Optimizing for term: 'life expectancy'\n",
      "life expectancy 0.219111890744 0.270955747088\n",
      "Optimizing for term: 'obesity'\n",
      "obesity 0.0 0.0\n",
      "Optimizing for term: 'religion'\n",
      "religion 0.654816960796 0.703854430075\n",
      "Optimizing for term: 'migration'\n",
      "migration 0.0460788714307 0.382136203191\n",
      "Optimizing for term: 'poverty'\n",
      "poverty 0.508164996135 0.509743293218\n",
      "Optimizing for term: 'social media'\n",
      "social media 0.0190992928695 0.933051296691\n",
      "Optimizing for term: 'employment'\n",
      "employment 0.0 0.556966305734\n",
      "************************************\n",
      "model= ons_model_9\n",
      "************************************\n",
      "Optimizing for term: 'rpi'\n",
      "rpi 0.354260957047 0.767224222721\n",
      "Optimizing for term: 'gender pay gap'\n",
      "gender pay gap 0.381042769502 0.382396093272\n",
      "Optimizing for term: 'cpi'\n",
      "cpi 0.0 0.0742005488659\n",
      "Optimizing for term: 'gdp'\n",
      "gdp 0.160267182088 0.843969137316\n",
      "Optimizing for term: 'inflation'\n",
      "inflation 0.0362420823471 0.0362420823471\n",
      "Optimizing for term: 'crime'\n",
      "crime 0.143067110208 0.681805107045\n",
      "Optimizing for term: 'unemployment'\n",
      "unemployment 0.215936238385 0.215936238385\n",
      "Optimizing for term: 'population'\n",
      "population 0.0 0.0531185029791\n",
      "Optimizing for term: 'immigration'\n",
      "immigration 0.456859258023 0.456859258023\n",
      "Optimizing for term: 'mental health'\n",
      "mental health 0.501562500062 0.501562500062\n",
      "Optimizing for term: 'london'\n",
      "london 0.0476104922472 0.412581172408\n",
      "Optimizing for term: 'london population'\n",
      "london population 0.0 0.945758380084\n",
      "Optimizing for term: 'retail price index'\n",
      "retail price index 0.01789268271 0.643158647095\n",
      "Optimizing for term: 'life expectancy'\n",
      "life expectancy 0.218965709669 0.569513624567\n",
      "Optimizing for term: 'obesity'\n",
      "obesity 0.0 0.0\n",
      "Optimizing for term: 'religion'\n",
      "religion 0.654906862714 0.703668664481\n",
      "Optimizing for term: 'migration'\n",
      "migration 0.0458278974591 0.233444447927\n",
      "Optimizing for term: 'poverty'\n",
      "poverty 0.497389945727 0.509743293218\n",
      "Optimizing for term: 'social media'\n",
      "social media 0.0171233752585 0.848665100297\n",
      "Optimizing for term: 'employment'\n",
      "employment 0.0 0.0802667507106\n"
     ]
    }
   ],
   "source": [
    "# Individual models\n",
    "from skopt import gp_minimize\n",
    "\n",
    "results = {}\n",
    "# models = [\"ons_model_%d\" % (i+1) for i in range(9)]\n",
    "models = [\"ons_model_%d\" % i for i in [3,9]]\n",
    "\n",
    "for model in models:\n",
    "    print \"************************************\"\n",
    "    print \"model=\", model\n",
    "    print \"************************************\"\n",
    "    for searchTerm in searchTerms:\n",
    "    # searchTerm = \"rpi\"\n",
    "\n",
    "        x0 = [(0.0, 1.0), (0.0, 1.0), (0.0, 10.0)]\n",
    "        termFn = lambda x: optFn(searchTerm, model, x)\n",
    "\n",
    "        print \"Optimizing for term: '%s'\" % searchTerm\n",
    "        res = gp_minimize(termFn, x0, n_calls=20, verbose=False)\n",
    "\n",
    "        ndcgBefore = fn(searchTerm, model, (1.0, 0.5, 1.0))\n",
    "        ndcgAfter = fn(searchTerm, model, res.x)\n",
    "        if (ndcgAfter > ndcgBefore and ndcgAfter > 0.5):\n",
    "            if (model not in results):\n",
    "                results[model] = []\n",
    "            results[model].append(res.x)\n",
    "\n",
    "        print searchTerm, ndcgBefore, ndcgAfter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fnMultiple(searchTerm, models, X, doPrint=False):\n",
    "    rescoreQueries = []\n",
    "    for model,params in zip(models, np.split(np.array(X), len(models))):\n",
    "        b,q,r = params\n",
    "#     ndcg = processTerm(term, boosts, queryWeights, rescoreWeights)\n",
    "        rescoreQuery = queries.getRescoreQueriesForModel(store, searchTerm, model,\n",
    "                            b, q, r)\n",
    "        rescoreQueries.append(rescoreQuery)\n",
    "    ndcg = processTerm(searchTerm, rescoreQueries)\n",
    "    if (ndcg is None):\n",
    "        return 0.0\n",
    "    return ndcg\n",
    "\n",
    "def optFnMultiple(searchTerm, models, X):\n",
    "    ndcg = fnMultiple(searchTerm, models, X)\n",
    "    if (ndcg is None):\n",
    "        return 1.0\n",
    "    return 1.0 - ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************\n",
      "models= ['ons_model_3', 'ons_model_9']\n",
      "************************************\n",
      "Optimizing for term: 'rpi'\n",
      "rpi 0.354260957047 0.767224222721\n",
      "Optimizing for term: 'gender pay gap'\n",
      "gender pay gap 0.381042769502 0.381042769502\n",
      "Optimizing for term: 'cpi'\n",
      "cpi 0.0 1.0\n",
      "Optimizing for term: 'gdp'\n",
      "gdp 0.160267182088 0.855459211232\n",
      "Optimizing for term: 'inflation'\n",
      "inflation 0.0362420823471 0.354376658565\n",
      "Optimizing for term: 'crime'\n",
      "crime 0.143067110208 0.747571841401\n",
      "Optimizing for term: 'unemployment'\n",
      "unemployment 0.215936238385 0.215936238385\n",
      "Optimizing for term: 'population'\n",
      "population 0.0 0.713476287431\n",
      "Optimizing for term: 'immigration'\n",
      "immigration 0.456859258023 0.767874542656\n",
      "Optimizing for term: 'mental health'\n",
      "mental health 0.501562500062 0.434722508183\n",
      "Optimizing for term: 'london'\n",
      "london 0.0476104922472 0.507852506166\n",
      "Optimizing for term: 'london population'\n",
      "london population 0.0 0.945758380084\n",
      "Optimizing for term: 'retail price index'\n",
      "retail price index 0.01789268271 0.643158647095\n",
      "Optimizing for term: 'life expectancy'\n",
      "life expectancy 0.218965709669 0.569513624567\n",
      "Optimizing for term: 'obesity'\n",
      "obesity 0.0 0.0\n",
      "Optimizing for term: 'religion'\n",
      "religion 0.654906862714 0.703812471544\n",
      "Optimizing for term: 'migration'\n",
      "migration 0.0458278974591 0.382136203191\n",
      "Optimizing for term: 'poverty'\n",
      "poverty 0.497389945727 0.509743293218\n",
      "Optimizing for term: 'social media'\n",
      "social media 0.0171233752585 0.933051296691\n",
      "Optimizing for term: 'employment'\n",
      "employment 0.0 0.556966305734\n"
     ]
    }
   ],
   "source": [
    "# Combined models\n",
    "from skopt import gp_minimize\n",
    "\n",
    "results = []\n",
    "# models = [\"ons_model_%d\" % (i+1) for i in range(9)]\n",
    "models = [\"ons_model_%d\" % i for i in [3,9]]\n",
    "\n",
    "print \"************************************\"\n",
    "print \"models=\", models\n",
    "print \"************************************\"\n",
    "for searchTerm in searchTerms:\n",
    "# searchTerm = \"rpi\"\n",
    "\n",
    "    x0 = [(0.0, 1.0), (0.0, 1.0), (0.0, 10.0)]*len(models)\n",
    "    termFn = lambda x: optFnMultiple(searchTerm, models, x)\n",
    "    print \"Optimizing for term: '%s'\" % searchTerm\n",
    "    res = gp_minimize(termFn, x0, n_calls=20, verbose=False)\n",
    "\n",
    "    ndcgBefore = fn(searchTerm, model, (1.0, 0.5, 1.0))\n",
    "    ndcgAfter = fnMultiple(searchTerm, models, res.x)\n",
    "    if (ndcgAfter > ndcgBefore):\n",
    "        results.append(res.x)\n",
    "    print searchTerm, ndcgBefore, ndcgAfter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************\n",
      "ons_model_3\n",
      "************************************\n",
      "b,q,r= 0.631887623475 0.125649338855 8.4576390003\n",
      "************************************\n",
      "rpi 0.356155262372 0.87665301811\n",
      "gender pay gap 0.382189500006 0.381482333678\n",
      "cpi 0.0 0.534620806825\n",
      "gdp 0.16262626861 0.855457341681\n",
      "inflation 0.0378723031188 0.354318754639\n",
      "crime 0.176642282231 0.634061433544\n",
      "unemployment 0.162617662551 0.162617662551\n",
      "population 0.0 0.630901365609\n",
      "immigration 0.456780739083 0.456780739083\n",
      "mental health 0.512500000497 0.430651997216\n",
      "london 0.0898870302992 0.50811007846\n",
      "london population 0.12898119146 0.92225414832\n",
      "retail price index 0.0415243142619 0.601811239855\n",
      "life expectancy 0.228727777804 0.623829111225\n",
      "obesity 0.0 0.0\n",
      "religion 0.654816960796 0.464688610168\n",
      "migration 0.0480114556061 0.148777817248\n",
      "poverty 0.508164996135 0.508164996135\n",
      "social media 0.0173036505918 0.932409869746\n",
      "employment 0.0 0.295065124264\n",
      "************************************\n",
      "ons_model_9\n",
      "************************************\n",
      "b,q,r= 0.36372590926 0.142143428005 7.04067788937\n",
      "************************************\n",
      "rpi 0.356146510737 0.765776177363\n",
      "gender pay gap 0.381344038499 0.381484356825\n",
      "cpi 0.0 0.0\n",
      "gdp 0.160264666305 0.160267182088\n",
      "inflation 0.0370843059288 0.0362420823471\n",
      "crime 0.143854525553 0.34560498879\n",
      "unemployment 0.21582871965 0.215936238385\n",
      "population 0.0 0.0\n",
      "immigration 0.456859258023 0.456859258023\n",
      "mental health 0.512500000497 0.379400131115\n",
      "london 0.0679613965191 0.201473351554\n",
      "london population 0.0570700817232 0.851940541778\n",
      "retail price index 0.01789268271 0.643158647095\n",
      "life expectancy 0.220139297464 0.568795178139\n",
      "obesity 0.0 0.0\n",
      "religion 0.654906862714 0.654906862714\n",
      "migration 0.0497563845439 0.109136555349\n",
      "poverty 0.497389945727 0.497389945727\n",
      "social media 0.0171233752585 0.380327928431\n",
      "employment 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print \"************************************\"\n",
    "    print model\n",
    "    print \"************************************\"\n",
    "    for searchTerm in searchTerms:\n",
    "        sumB = sumQ = sumR = 0.0\n",
    "        count = 0.0\n",
    "        if (len(results[model]) > 0):\n",
    "            for result in results[model]:\n",
    "                b,q,r = result\n",
    "                sumB += b\n",
    "                sumQ += q\n",
    "                sumR += r\n",
    "                count += 1.0\n",
    "\n",
    "    avgB = sumB/count\n",
    "    avgQ = sumQ/count\n",
    "    avgR = sumR/count\n",
    "\n",
    "    print 'b,q,r=', avgB, avgQ, avgR\n",
    "    print \"************************************\"\n",
    "    for searchTerm in searchTerms:\n",
    "        print searchTerm, fn(searchTerm, model, (1.0, 0.5, 1.0)), fn(searchTerm, model, (avgB, avgQ, avgR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rpi 0.767224222721\n",
      "gender pay gap 0.381042769502\n",
      "cpi 0.0742005488659\n",
      "gdp 0.843969137316\n",
      "inflation 0.0362420823471\n",
      "crime 0.681805107045\n",
      "unemployment 0.215936238385\n",
      "population 0.0260982709755\n",
      "immigration 0.456859258023\n",
      "mental health 0.434722508183\n",
      "london 0.412581172408\n",
      "london population 0.945758380084\n",
      "retail price index 0.643158647095\n",
      "life expectancy 0.569513624567\n",
      "obesity 0.0\n",
      "religion 0.703668664481\n",
      "migration 0.143960006606\n",
      "poverty 0.497389945727\n",
      "social media 0.848665100297\n",
      "employment 0.0802667507106\n"
     ]
    }
   ],
   "source": [
    "reload(queries)\n",
    "\n",
    "for searchTerm in searchTerms:\n",
    "    rescoreQueries = []\n",
    "    \n",
    "    for model in results:\n",
    "        sumB = sumQ = sumR = 0.0\n",
    "        count = 0.0\n",
    "        if (len(results[model]) > 0):\n",
    "            for result in results[model]:\n",
    "                b,q,r = result\n",
    "                sumB += b\n",
    "                sumQ += q\n",
    "                sumR += r\n",
    "                count += 1.0\n",
    "\n",
    "        avgB = sumB/count\n",
    "        avgQ = sumQ/count\n",
    "        avgR = sumR/count\n",
    "\n",
    "#         print searchTerm, fn(searchTerm, model, (1.0, 0.5, 1.0)), fn(searchTerm, model, (avgB, avgQ, avgR))\n",
    "        rescoreQuery = queries.getRescoreQueryForModel(store, searchTerm, model, avgB, avgQ, avgR)\n",
    "        rescoreQueries.append(rescoreQuery)\n",
    "        \n",
    "    ndcgAll = processTerm(searchTerm, rescoreQueries)\n",
    "    print searchTerm, ndcgAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fn(searchTerm, X, doPrint=False):\n",
    "#     b,q,r = np.split(np.array(X), 3)\n",
    "#     if (doPrint): print 'b,q,r', b, q, r\n",
    "# #     ndcg = processTerm(term, boosts, queryWeights, rescoreWeights)\n",
    "#     ndcg = processTerm(searchTerm, b, q, r)\n",
    "#     if (ndcg is None):\n",
    "#         return 0.0\n",
    "#     return ndcg\n",
    "\n",
    "# def optFn(searchTerm, X):\n",
    "#     ndcg = fn(searchTerm, X)\n",
    "#     if (ndcg is None):\n",
    "#         return 1.0\n",
    "#     return 1.0 - ndcg\n",
    "\n",
    "# standardBQR = np.array([[1.0]*len(models), [0.5]*len(models), [1.0]*len(models)]).flatten()\n",
    "# ndcgBefore = fn(\"rpi\", standardBQR, doPrint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rpi\n",
      "Optimizing for term  rpi\n",
      "rpi 0.765749872378 0.761125832596\n",
      "gender pay gap\n",
      "Optimizing for term  gender pay gap\n",
      "gender pay gap 0.381042769502 0.381042769502\n",
      "cpi\n",
      "Optimizing for term  cpi\n",
      "cpi 0.0 0.0742005488659\n",
      "gdp\n",
      "Optimizing for term  gdp\n"
     ]
    }
   ],
   "source": [
    "# from skopt import gp_minimize\n",
    "\n",
    "# for searchTerm in searchTerms:\n",
    "#     print searchTerm\n",
    "# # searchTerm = \"rpi\"\n",
    "\n",
    "#     x0 = [(0.0, 1.0)]*len(models)\n",
    "#     x0.extend([(0.0, 1.0)]*len(models))\n",
    "#     x0.extend([(0.0, 10.0)]*len(models))\n",
    "#     termFn = lambda x: optFn(searchTerm, x)\n",
    "\n",
    "#     print \"Optimizing for term \", searchTerm\n",
    "#     res = gp_minimize(termFn, x0, n_calls=20, verbose=False)\n",
    "    \n",
    "#     ndcgBefore = fn(searchTerm, standardBQR)\n",
    "#     ndcgAfter = fn(searchTerm, res.x)\n",
    "\n",
    "#     print searchTerm, ndcgBefore, ndcgAfter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rpi 0.356146510737 0.767224222721\n"
     ]
    }
   ],
   "source": [
    "for key in resDict:\n",
    "    res = resDict[key]\n",
    "#     print res.fun, res.x\n",
    "\n",
    "    ndcgBefore = fn(searchTerm, [1.0, 0.5, 1.0])\n",
    "    ndcgAfter = fn(searchTerm, res.x)\n",
    "\n",
    "    print key, ndcgBefore, ndcgAfter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "[0.91512786228791776, 0.18637723563018363, 0.092858794570568129, 0.53273612668253156,\n",
    " 0.76706400990704571, 0.58349107122737787, 0.6834580839907477, 0.88558707199299047,\n",
    " 0.48277903739251804, 6.1817401341518003, 9.7805931268469362, 9.3722047829479767,\n",
    " 4.713174354828487, 2.601749548125281, 4.3597225473416383, 8.9907343794135848,\n",
    " 6.4090652493697053, 2.9974113081044855]\n",
    "\n",
    "Out[53]:\n",
    "0.76181999486796548"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
