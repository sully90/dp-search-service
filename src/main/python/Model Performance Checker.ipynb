{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseUrl = \"http://localhost:20000/\"\n",
    "\n",
    "import urllib, urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "from modules.ONS import utils as search_utils\n",
    "reload(search_utils)\n",
    "\n",
    "class ONSScraper(object):\n",
    "    def __init__(self, baseUrl):\n",
    "        if (baseUrl.endswith(\"/\")):\n",
    "            baseUrl = str(baseUrl)[:-1]\n",
    "        self.baseUrl = baseUrl\n",
    "        \n",
    "    def getPage(self, extension):\n",
    "        targetUrl = self.baseUrl + extension\n",
    "        page = urllib2.urlopen(targetUrl)\n",
    "        return BeautifulSoup(page)\n",
    "        \n",
    "    def searchResultsList(self, searchTerm, method, **kwargs):\n",
    "        page = method(searchTerm, **kwargs)\n",
    "        divElements = page.select(\"div.search-results\")\n",
    "        if (len(divElements) == 1):\n",
    "            ulElements = divElements[0].select(\"ul.list--neutral\")\n",
    "            if (len(ulElements) == 1):\n",
    "                liElements = ulElements[0].select(\"li.search-results__item\")\n",
    "                \n",
    "                results = []\n",
    "                for elem in liElements:\n",
    "                    href = elem.select(\"a\")[0].attrs[\"href\"]\n",
    "                    results.append(href)\n",
    "                return results\n",
    "        return None\n",
    "\n",
    "onsScraper = ONSScraper(baseUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient, ASCENDING, DESCENDING\n",
    "client = MongoClient('localhost', 27017)\n",
    "\n",
    "db = client.local\n",
    "collection = db.judgements\n",
    "\n",
    "def mergeDicts(x, y):\n",
    "    z = x.copy()   # start with x's keys and values\n",
    "    z.update(y)    # modifies z with y's keys and values & returns None\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "searchTerms = [\"rpi\", \"gender pay gap\", \"cpi\", \"gdp\", \"inflation\", \"crime\", \"unemployment\", \n",
    "              \"population\", \"immigration\", \"mental health\", \"london\", \"london population\", \n",
    "              \"retail price index\", \"life expectancy\", \"obesity\", \"religion\", \"migration\", \n",
    "              \"poverty\", \"social media\", \"employment\"]\n",
    "models = []\n",
    "for i in range(9):\n",
    "    models.append(\"ons_model_%d\" % (i+1))\n",
    "models.append(\"all\")\n",
    "\n",
    "def termQuery(term):\n",
    "    return {\"term\": term}\n",
    "\n",
    "def timeQuery(dateTime):\n",
    "    return {\"timeStamp\": dateTime}\n",
    "\n",
    "# Get date of most recent entries\n",
    "doc = collection.find().sort([(\"timeStamp\", DESCENDING)]).limit(1).next()\n",
    "timeStamp = doc[\"timeStamp\"]\n",
    "    \n",
    "timeStampQuery = timeQuery(timeStamp)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "MAX_SCORE = 4.0\n",
    "\n",
    "def idealJudgement(num):\n",
    "    i = 0\n",
    "    incremenet = (1.0 / (float(num) - 1.0)) * num\n",
    "    \n",
    "    iJ = np.zeros(num)\n",
    "    val = len(iJ)\n",
    "    while (val > 0):\n",
    "        iJ[i] = (val / float(num)) * MAX_SCORE\n",
    "        i += 1\n",
    "        val -= incremenet\n",
    "        \n",
    "    return iJ\n",
    "\n",
    "def idealDiscountedCumulativeGain(num):\n",
    "    idealGain = idealJudgement(num)\n",
    "    iDCG = np.zeros(num)\n",
    "    \n",
    "    total = 0.0\n",
    "    for i in range(num):\n",
    "        total += idealGain[i] / float(i+1)\n",
    "        iDCG[i] = total\n",
    "    return iDCG\n",
    "\n",
    "class Judgements(object):\n",
    "    def __init__(self, qid, judgements):\n",
    "        self.qid = qid\n",
    "        self.judgements = judgements\n",
    "        \n",
    "    def dcg(self):\n",
    "        total = 0.0\n",
    "        \n",
    "        dcg = []\n",
    "        \n",
    "        for i in range(len(self.judgements)):\n",
    "            judgement = self.judgements[i]\n",
    "            total += judgement[\"judgement\"] / float(judgement[\"rank\"])\n",
    "            dcg.append(total)\n",
    "            \n",
    "        return np.array(dcg)\n",
    "    \n",
    "    def ndcg(self):\n",
    "        \n",
    "        dcg = self.dcg()\n",
    "        idcg = idealDiscountedCumulativeGain(len(dcg))\n",
    "        \n",
    "        ndcg = np.zeros(len(dcg))\n",
    "        \n",
    "        for i in range(len(ndcg)):\n",
    "            ndcg[i] = min(1.0, dcg[i] / idcg[i])\n",
    "        return ndcg\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.judgements.__iter__()\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.judgements[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.judgements)\n",
    "    \n",
    "    def remove(self, item):\n",
    "        self.judgements.remove(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ***********************************************\n",
      "rpi\n",
      "***********************************************\n",
      "ons_model_1 0.00625000004657\n",
      "ons_model_2 0.01337037047\n",
      "ons_model_3 0.749187714201\n",
      "ons_model_4 0.00157126824964\n",
      "ons_model_5 0.00907293102325\n",
      "ons_model_7 0.00833333339542\n",
      "ons_model_8 0.00753233397734\n",
      "ons_model_9 0.796919538895\n",
      "all 0.795164537127\n"
     ]
    }
   ],
   "source": [
    "import copy, jwt\n",
    "from urllib2 import HTTPError\n",
    "reload(search_utils)\n",
    "\n",
    "def getUriFromJwtToken(token):\n",
    "    jwtDecodedDict = jwt.decode(token, 'secret', algorithms=['HS256'])\n",
    "    return jwtDecodedDict[\"uri\"]\n",
    "\n",
    "qid = 0\n",
    "for searchTerm in searchTerms:\n",
    "    qid += 1\n",
    "    print \"***********************************************\"\n",
    "    print searchTerm\n",
    "    print \"***********************************************\"\n",
    "    # Load the judgements\n",
    "    query = mergeDicts(termQuery(searchTerm), timeStampQuery)\n",
    "    cursor = collection.find(query)\n",
    "    count = cursor.count()\n",
    "    \n",
    "    if (count > 0):\n",
    "        judgements = cursor.next()\n",
    "        \n",
    "        # Get search results for each model\n",
    "        for model in models:\n",
    "            # Crawl the website\n",
    "            modelJudgements = copy.deepcopy(judgements)\n",
    "\n",
    "            # Scrape new ranks\n",
    "            judgementList = modelJudgements[\"judgements\"][\"judgementList\"]\n",
    "            keep = []\n",
    "#             judgementList = Judgements(qid, modelJudgements[\"judgements\"][\"judgementList\"])\n",
    "            for page in range(1, 10):\n",
    "                try:\n",
    "                    searchResults = onsScraper.searchResultsList(searchTerm, search_utils.sltr, \n",
    "                                            model=model, size=10, page=page, verbose=False)\n",
    "    \n",
    "                    searchResultsDecoded = []\n",
    "                    for searchResult in searchResults:\n",
    "                        token = searchResult.replace(\"/redir/\", \"\")\n",
    "                        uri = getUriFromJwtToken(token)\n",
    "                        searchResultsDecoded.append(uri)\n",
    "\n",
    "                    for judgement in judgementList:\n",
    "                        judgement[\"rank\"] = -1\n",
    "                        url = judgement[\"attrs\"][\"uri\"]\n",
    "                        if (url in searchResultsDecoded):\n",
    "                            newRank = int(((page - 1) * 10.0) + searchResultsDecoded.index(url) + 1)\n",
    "                            judgement[\"rank\"] = newRank\n",
    "                            j = copy.deepcopy(judgement)\n",
    "                            j[\"rank\"] = newRank\n",
    "                            keep.append(j)\n",
    "                    \n",
    "                except HTTPError:\n",
    "                    break\n",
    "                    \n",
    "            if (len(keep) > 1):\n",
    "                judgementList = Judgements(qid, keep)\n",
    "                print model, judgementList.ndcg().mean()\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
